{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| type           |   tokens |   message_len |   message |    cost |\n",
      "|:---------------|---------:|--------------:|----------:|--------:|\n",
      "| Prompt model   | 234114   |        936455 |        98 | 3.51171 |\n",
      "| Response model |  10704.5 |         42818 |        96 | 0.64227 |\n",
      "| Total          | 244818   |        979273 |       194 | 4.15398 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/d6hm8fk11h9g15w0kqn92kwm0000gp/T/ipykernel_94235/1544061974.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the log file and create a DataFrame\n",
    "# Read the log file\n",
    "# Example of log:\n",
    "# 2025-02-14 13:08:12,338 - INFO - Received prompt: \n",
    "# Consider this SKELETON_QUERY and these TABLES_SCHEMA:\n",
    "# \n",
    "# <SKELETON_QUERY>\n",
    "# SELECT\n",
    "# ...\n",
    "# 2025-02-14 14:12:09,757  - INFO - Prompt model|llama3|Ollama:\n",
    "# 2025-02-14 14:12:09,768 - INFO - Response model|llama3|Ollama:\n",
    "# Consider this SKELETON_QUERY and these TABLES_SCHEMA:\n",
    "# \n",
    "# <SKELETON_QUERY>\n",
    "# ...\n",
    "\n",
    "\n",
    "log_data = []\n",
    "current_entry = None\n",
    "\n",
    "# Regex pattern to match: \"YYYY-MM-DD HH:MM:SS,MMM - INFO - Message\"\n",
    "log_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2},\\d{3})\\s-\\s(INFO)\\s-\\s([^:]*?):\\s?(.*)')\n",
    "\n",
    "with open('../output/batch_009/app.log', 'r') as file:\n",
    "    for line in file:\n",
    "        # Check if line matches the timestamp pattern\n",
    "        match = log_pattern.match(line)\n",
    "        if match:\n",
    "            if current_entry:\n",
    "                log_data.append(current_entry)\n",
    "            # Extract groups from regex match\n",
    "            timestamp, level, type, message = match.groups()\n",
    "            current_entry = {\n",
    "                'timestamp': timestamp,\n",
    "                'level': level,\n",
    "                'type' : type,\n",
    "                'message': message.strip()\n",
    "            }\n",
    "        elif current_entry and line.strip():\n",
    "            # Append additional lines to the message\n",
    "            current_entry['message'] += '\\n' + line.strip()\n",
    "\n",
    "# Don't forget to add the last entry\n",
    "if current_entry:\n",
    "    log_data.append(current_entry)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(log_data)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Create model and platform columns by extracting from relevant rows\n",
    "df[['type', 'model', 'platform']] = df['type'].str.split('|', expand=True)\n",
    "# Fill NaN values for rows that don't contain model/platform info\n",
    "df['model'] = df['model'].fillna('')\n",
    "df['platform'] = df['platform'].fillna('')\n",
    "\n",
    "df['message_len']=df['message'].apply(len)\n",
    "df['tokens']=df['message_len']/4\n",
    "# Display the first few rows\n",
    "#print(df[['type','model','platform','message_len','tokens']].head(20).to_markdown())\n",
    "df['type'].value_counts()\n",
    "# Filter the DataFrame for 'Prompt model' and 'Response model'\n",
    "filtered_df = df[df['type'].isin(['Prompt model', 'Response model'])]\n",
    "\n",
    "# Group by 'type' and calculate the sum of 'tokens' and 'message_len'\n",
    "grouped_df = filtered_df.groupby('type').agg({'tokens': 'sum', 'message_len': 'sum','message':'count'}).reset_index()\n",
    "\n",
    "# Calculate the cost of the prompts in o1\n",
    "# Prompt model:  $15 / Million of tokens\n",
    "# Response model: $60 / Million of tokens\n",
    "\n",
    "grouped_df['cost'] = grouped_df.apply(lambda row: (row['tokens'] / 1_000_000) * (15 if row['type'] == 'Prompt model' else 60), axis=1)\n",
    "\n",
    "# Add a totals row\n",
    "totals = grouped_df[['tokens', 'message_len', 'message', 'cost']].sum()\n",
    "totals['type'] = 'Total'\n",
    "grouped_df = pd.concat([grouped_df, pd.DataFrame([totals])], ignore_index=True)\n",
    "\n",
    "print(grouped_df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
